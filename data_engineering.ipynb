{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('products.json') as f:\n",
    "    data1 = json.load(f)\n",
    "with open('productshandm.json') as f:\n",
    "    data2 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[0]\n",
    "unique_types = ['Backpacks',\n",
    "                'Belts',\n",
    "                'Bra',\n",
    "                'Capris',\n",
    "                'Caps-hats',\n",
    "                'Casual Shoes',\n",
    "                'Clutches',\n",
    "                'Dresses',\n",
    "                'Earrings',\n",
    "                'Flip Flops',\n",
    "                'Handbags',\n",
    "                'Heels',\n",
    "                'Jeans',\n",
    "                'Jewellery_Set',\n",
    "                'Kurtas',\n",
    "                'Leggings',\n",
    "                'Outwear',\n",
    "                'pijamas',\n",
    "                'Ring',\n",
    "                'Salwar',\n",
    "                'Sandals',\n",
    "                'Scarves',\n",
    "                'Shirts',\n",
    "                'Shorts',\n",
    "                'Skirts',\n",
    "                'Socks',\n",
    "                'Sports Shoes',\n",
    "                'Sunglasses',\n",
    "                'Sweatshirts',\n",
    "                'Swimwear',\n",
    "                'Tops',\n",
    "                'Track Pants',\n",
    "                'Tracksuits',\n",
    "                'Trousers',\n",
    "                'Tshirts',\n",
    "                'Tunics',\n",
    "                'Wallets',\n",
    "                'Watches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "# get image urls\n",
    "# from tensorflow.keras.utils import load_img, img_to_array\n",
    "# image_urls = []\n",
    "# for i in data1:\n",
    "#     for j in i['products']:\n",
    "\n",
    "#         image_urls.append(j['imageUrl'])\n",
    "\n",
    "\n",
    "# #add an  http: // to the beginning of each url\n",
    "# image_urls = [r'http://' + i for i in image_urls]\n",
    "# # Make a directory to store the images\n",
    "# os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# # Define a list of image URLs\n",
    "\n",
    "\n",
    "# # Loop through the list of URLs and download each image\n",
    "# for i, url in enumerate(image_urls):\n",
    "#     response = requests.get(url)\n",
    "#     open(f\"images/image{i}.jpg\", \"wb\").write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# # import io\n",
    "# import io\n",
    "\n",
    "\n",
    "# # Directory to save the images\n",
    "# save_dir = \"imagesFromAsos\"\n",
    "\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "\n",
    "# # Loop over the image URLs\n",
    "# for url in image_urls:\n",
    "#     response = requests.get(url)\n",
    "#     binary_image = response.content\n",
    "\n",
    "#     # Convert binary image data to a PIL Image object\n",
    "#     image = Image.open(io.BytesIO(binary_image))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import final model and classify the images\n",
    "from keras.models import load_model, model_from_json\n",
    "json_file = open('final_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"final_model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the images and save the label and the image name in a dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# get the image names\n",
    "image_names = os.listdir('asos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['27384.jpg',\n",
       " '27385.jpg',\n",
       " '27386.jpg',\n",
       " '36249.jpg',\n",
       " '36250.jpg',\n",
       " '36251.jpg',\n",
       " '36252.jpg',\n",
       " '36253.jpg',\n",
       " '36254.jpg',\n",
       " '36255.jpg',\n",
       " '36256.jpg',\n",
       " '36257.jpg',\n",
       " '36258.jpg',\n",
       " '36259.jpg',\n",
       " '36260.jpg',\n",
       " '36261.jpg',\n",
       " '36262.jpg',\n",
       " '36263.jpg',\n",
       " '36264.jpg',\n",
       " '36265.jpg',\n",
       " '36266.jpg',\n",
       " '36267.jpg',\n",
       " '36268.jpg',\n",
       " '36269.jpg',\n",
       " '36270.jpg',\n",
       " '36271.jpg',\n",
       " '36272.jpg',\n",
       " '36273.jpg',\n",
       " '36274.jpg',\n",
       " '36275.jpg',\n",
       " '36276.jpg',\n",
       " '36277.jpg',\n",
       " '36278.jpg',\n",
       " '36279.jpg',\n",
       " '36280.jpg',\n",
       " '36281.jpg',\n",
       " '36282.jpg',\n",
       " '36283.jpg',\n",
       " '36284.jpg',\n",
       " '36285.jpg',\n",
       " '36286.jpg',\n",
       " '36287.jpg',\n",
       " '36288.jpg',\n",
       " '36289.jpg',\n",
       " '36290.jpg',\n",
       " '43460.jpg',\n",
       " '43461.jpg',\n",
       " '43462.jpg',\n",
       " '43463.jpg',\n",
       " '43464.jpg',\n",
       " '43465.jpg',\n",
       " '43466.jpg',\n",
       " '43467.jpg',\n",
       " '43468.jpg',\n",
       " '43469.jpg',\n",
       " '43470.jpg',\n",
       " '43471.jpg',\n",
       " '43472.jpg',\n",
       " '45085.jpg',\n",
       " '45086.jpg',\n",
       " '45095.jpg',\n",
       " '49779.jpg',\n",
       " '49780.jpg',\n",
       " '49781.jpg',\n",
       " '49782.jpg',\n",
       " '49783.jpg',\n",
       " '49784.jpg',\n",
       " '49785.jpg',\n",
       " '49786.jpg',\n",
       " '52017.jpg',\n",
       " '52415.jpg',\n",
       " '52416.jpg',\n",
       " '52417.jpg',\n",
       " '55791.jpg',\n",
       " '55794.jpg',\n",
       " '55795.jpg',\n",
       " '55796.jpg',\n",
       " '55802.jpg',\n",
       " '55803.jpg',\n",
       " '55804.jpg',\n",
       " '55805.jpg',\n",
       " '55806.jpg',\n",
       " '55807.jpg',\n",
       " '55809.jpg',\n",
       " '55810.jpg',\n",
       " '55811.jpg',\n",
       " '55812.jpg',\n",
       " '55813.jpg',\n",
       " '55814.jpg',\n",
       " '55817.jpg',\n",
       " '55818.jpg',\n",
       " '55819.jpg',\n",
       " '55821.jpg',\n",
       " '55822.jpg',\n",
       " '55823.jpg',\n",
       " '55824.jpg',\n",
       " '56221.jpg',\n",
       " '56222.jpg',\n",
       " '56223.jpg',\n",
       " '56224.jpg',\n",
       " '56225.jpg',\n",
       " '56226.jpg',\n",
       " '56227.jpg',\n",
       " '56228.jpg',\n",
       " '56229.jpg',\n",
       " '56230.jpg',\n",
       " '56231.jpg',\n",
       " '56232.jpg',\n",
       " '56233.jpg',\n",
       " '56234.jpg',\n",
       " '56235.jpg',\n",
       " '56236.jpg',\n",
       " '56237.jpg',\n",
       " '56238.jpg',\n",
       " '56239.jpg',\n",
       " '56240.jpg',\n",
       " '56241.jpg',\n",
       " '56243.jpg',\n",
       " '56244.jpg',\n",
       " '56245.jpg',\n",
       " '56247.jpg',\n",
       " '56248.jpg',\n",
       " '56249.jpg',\n",
       " '56250.jpg',\n",
       " '56251.jpg',\n",
       " '56252.jpg',\n",
       " '56253.jpg',\n",
       " '56254.jpg',\n",
       " '56255.jpg',\n",
       " '56256.jpg',\n",
       " '56257.jpg',\n",
       " '56258.jpg',\n",
       " '56260.jpg',\n",
       " '56261.jpg',\n",
       " '56262.jpg',\n",
       " '56263.jpg',\n",
       " '56265.jpg',\n",
       " '56266.jpg',\n",
       " '56267.jpg',\n",
       " '56268.jpg',\n",
       " '56269.jpg']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   # get the first 3 highest probabilities\n",
    "#     top_3 = np.argsort(prediction[0])[:-4:-1]\n",
    "#     # put a threshold of 0.7\n",
    "#     if prediction[0][top_3[0]] < 0.7:\n",
    "#         top_3 = np.array([0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import cv2\n",
    "from keras.models import load_model, model_from_json\n",
    "\n",
    "def import_and_predict(image_data, model):\n",
    "    size = (224, 224)\n",
    "    image = Image.open(image_data)\n",
    "    image = ImageOps.fit(image, size, Image.LANCZOS)\n",
    "    image = np.asarray(image)   \n",
    "    # img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_reshape = img[np.newaxis, ...]\n",
    "    img_reshape = img_reshape[..., np.newaxis]\n",
    "    prediction = model.predict(img_reshape)\n",
    "    # get the first 3 highest probabilities\n",
    "    top_3 = np.argsort(prediction[0])[:-4:-1]\n",
    "    # put a threshold of 0.7\n",
    "    if prediction[0][top_3[0]] < 0.7:\n",
    "        top_3 = np.array([0, 0, 0])\n",
    "\n",
    "    print(top_3)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_names\n",
    "# predict the labels\n",
    "labels = []\n",
    "image_names = os.listdir('finalDataset/pijamas/')\n",
    "for i in image_names[:30]:\n",
    "    # try:\n",
    "   import_and_predict('finalDataset/pijamas/' + i, model)\n",
    "   labels.append(unique_types[np.argmax(\n",
    "       import_and_predict('finalDataset/pijamas/' + i, model))])\n",
    "\n",
    "# create a dataframe with one colum for image names and one column for labels    \n",
    "df = pd.DataFrame({'image_name': image_names[:30], 'label': labels})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the folder names form finalDataset\n",
    "\n",
    "folder_names = os.listdir('finalDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names\n",
    "# create folders for each label in asos\n",
    "for i in unique_types:\n",
    "    os.makedirs(\"asos/\" + i, exist_ok=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#folderpath= r'C:\\Users\\mrpal\\OneDrive\\Desktop\\WBS\\machineLearning\\supervised\\deeplearning\\Imagesfromfashiondataset\\only'\n",
    "# # for each row in the dataframe\n",
    "# for index, row in selected_styles.iterrows():\n",
    "#     # get the image name\n",
    "#     image_name = row['image_name']\n",
    "#     # get the type of clothing\n",
    "#     type = row['articleType']\n",
    "#     # get the source path to the image\n",
    "#     src = os.path.join(r\"folderpath\", image_name).replace(\"\\\\\", \"/\")\n",
    "\n",
    "#     # get the destination path to the image\n",
    "#     dst = r'Imagesfromfashiondataset/'+os.path.join(type, image_name).replace(\"\\\\\", \"/\")\n",
    "#     # move the image from the source to the destination\n",
    "#     # print(src, dst)\n",
    "#     shutil.move(src, dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5d44d20471fed6b31c84e96a507e39677b7979bf00486c2e6552218c91082f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
