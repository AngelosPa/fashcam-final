{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('products.json') as f:\n",
    "    data1 = json.load(f)\n",
    "# with open('productshandm.json') as f:\n",
    "#     data2 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[0]\n",
    "unique_types = ['Backpacks',\n",
    "                'Belts',\n",
    "                'Bra',\n",
    "                'Capris',\n",
    "                'Caps-hats',\n",
    "                'Casual Shoes',\n",
    "                'Clutches',\n",
    "                'Dresses',\n",
    "                'Earrings',\n",
    "                'Flip Flops',\n",
    "                'Handbags',\n",
    "                'Heels',\n",
    "                'Jeans',\n",
    "                'Jewellery_Set',\n",
    "                'Kurtas',\n",
    "                'Leggings',\n",
    "                'Outwear',\n",
    "                'pijamas',\n",
    "                'Ring',\n",
    "                'Salwar',\n",
    "                'Sandals',\n",
    "                'Scarves',\n",
    "                'Shirts',\n",
    "                'Shorts',\n",
    "                'Skirts',\n",
    "                'Socks',\n",
    "                'Sports Shoes',\n",
    "                'Sunglasses',\n",
    "                'Sweatshirts',\n",
    "                'Swimwear',\n",
    "                'Tops',\n",
    "                'Track Pants',\n",
    "                'Tracksuits',\n",
    "                'Trousers',\n",
    "                'Tshirts',\n",
    "                'Tunics',\n",
    "                'Wallets',\n",
    "                'Watches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "# get image urls\n",
    "# from tensorflow.keras.utils import load_img, img_to_array\n",
    "# image_urls = []\n",
    "# for i in data1:\n",
    "#     for j in i['products']:\n",
    "\n",
    "#         image_urls.append(j['imageUrl'])\n",
    "\n",
    "\n",
    "# #add an  http: // to the beginning of each url\n",
    "# image_urls = [r'http://' + i for i in image_urls]\n",
    "# # Make a directory to store the images\n",
    "# os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# # Define a list of image URLs\n",
    "\n",
    "\n",
    "# # Loop through the list of URLs and download each image\n",
    "# for i, url in enumerate(image_urls):\n",
    "#     response = requests.get(url)\n",
    "#     open(f\"images/image{i}.jpg\", \"wb\").write(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# # import io\n",
    "# import io\n",
    "\n",
    "\n",
    "# # Directory to save the images\n",
    "# save_dir = \"imagesFromAsos\"\n",
    "\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "\n",
    "# # Loop over the image URLs\n",
    "# for url in image_urls:\n",
    "#     response = requests.get(url)\n",
    "#     binary_image = response.content\n",
    "\n",
    "#     # Convert binary image data to a PIL Image object\n",
    "#     image = Image.open(io.BytesIO(binary_image))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import final model and classify the images\n",
    "from keras.models import load_model, model_from_json\n",
    "json_file = open('final_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"final_model.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the images and save the label and the image name in a dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "# get the image names\n",
    "image_names = os.listdir('asos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   # get the first 3 highest probabilities\n",
    "#     top_3 = np.argsort(prediction[0])[:-4:-1]\n",
    "#     # put a threshold of 0.7\n",
    "#     if prediction[0][top_3[0]] < 0.7:\n",
    "#         top_3 = np.array([0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "def import_and_predict(image_data, model):\n",
    "    size = (224, 224)\n",
    "    image = Image.open(image_data)\n",
    "    image = ImageOps.fit(image, size, Image.LANCZOS)\n",
    "    image = np.asarray(image)   \n",
    "    # img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_reshape = img[np.newaxis, ...]\n",
    "    img_reshape = img_reshape[..., np.newaxis]\n",
    "    prediction = model.predict(img_reshape)\n",
    "    # get the first 3 highest probabilities\n",
    "    top_3 = np.argsort(prediction[0])[:-4:-1]\n",
    "    # put a threshold of 0.7\n",
    "    if prediction[0][top_3[0]] < 0.7:\n",
    "        top_3 = np.array([0, 0, 0])\n",
    "\n",
    "    print(top_3)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_names\n",
    "# predict the labels\n",
    "labels = []\n",
    "image_names = os.listdir('finalDataset/pijamas/')\n",
    "for i in image_names[:30]:\n",
    "    # try:\n",
    "   import_and_predict('finalDataset/pijamas/' + i, model)\n",
    "   labels.append(unique_types[np.argmax(\n",
    "       import_and_predict('finalDataset/pijamas/' + i, model))])\n",
    "\n",
    "# create a dataframe with one colum for image names and one column for labels    \n",
    "df = pd.DataFrame({'image_name': image_names[:30], 'label': labels})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the folder names form finalDataset\n",
    "\n",
    "folder_names = os.listdir('finalDataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names\n",
    "# create folders for each label in asos\n",
    "for i in unique_types:\n",
    "    os.makedirs(\"asos/\" + i, exist_ok=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5d44d20471fed6b31c84e96a507e39677b7979bf00486c2e6552218c91082f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
